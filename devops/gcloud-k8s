##K8S
#https://cloud.google.com/kubernetes-engine/docs/tutorials/hello-app
#https://kubernetes.io/docs/tutorials/kubernetes-basics/
#https://cloud.google.com/code/docs/vscode/yaml-editing

#install kubeclt
gcloud components install kubectl

#build a full image with compiled code and service running of a project
docker build -t [IMAGE-NAME]/[PROJECT-NAME]:[VERSION] .

#push image to google cloud docker libraries
gcloud auth configure-docker
docker push IMAGE-NAME/PROJECT-NAME:VERSION


#Connect to server and create cluster

gcloud config set project $PROJECT_ID
gcloud config set compute/zone compute-zone

gcloud container clusters create [CLUSTER-NAME]
gcloud compute instances list


#deployment

kubectl create deployment [PROJECT-NAME] --image=[IMAGE-NAME]/[PROJECT-NAME]:[VERSION]
kubectl scale deployment [PROJECT-NAME] --replicas=3
kubectl autoscale deployment hello-app --cpu-percent=80 --min=1 --max=5

kubectl get pods
kubectl get nodes

#expose app to internet
kubectl expose [ENV] [PROJECT-NAME] --name=[PROJECT-NAME-SERVICE-NAME] --type=LoadBalancer --port 80 --target-port 8080
kubectl get service


#updating

#change origin code
docker build -t [IMAGE-NAME]/[PROJECT-NAME]:[VERSION2] .
docker push [IMAGE-NAME]/[PROJECT-NAME]:[VERSION2]
kubectl set image [ENV]/[PROJECT-NAME]=[IMAGE-NAME]/[PROJECT-NAME]:[VERSION2]
watch kubectl get pods


#deleting

kubectl delete service [PROJECT-NAME-SERVICE-NAME]
gcloud container clusters delete [CLUSTER-NAME]


###############

#LOGIN
#web based login
gcloud auth login

#login keyfile
gcloud auth activate-service-account --key-file [KEY_FILE]

#list
bq ls

#https://cloud.google.com/bigquery/bq-command-line-tool

#delete table -t for table -f for force
bq rm -f -t [PROJECT_ID]:[DATASET].[TABLE]

#copy table from one project and workspace to another
bq cp [PROJECT_ID_1]:[DATASET].[TABLE] [PROJECT_ID_2]:[DATASET].[TABLE]


#expiracion de tablas - por segundos
bq update --expiration 3600 [PROJECT_ID]:[DATASET].[TABLE]
bq update --default_table_expiration 3600 [TABLE]

#create table
bq mk --table --expiration [INTEGER] --description [DESCRIPTION] --label [KEY:VALUE, KEY:VALUE] [PROJECT_ID]:[DATASET].[TABLE] [SCHEMA]

[SCHEMA] is an inline schema definition in the format [FIELD]:[DATA_TYPE],[FIELD]:[DATA_TYPE] or the path to the JSON schema file on your local machine.


#rsync from dir to google storage
gsutil rsync -n -dr -x "FILES|FILES" dir/ gs://bucket/subdir/

#rsync between buckets
gsutil -m rsync -rd gs://b1 gs://b2

#A series of really specific regular expressions solves the problem:
gsutil -m rsync -rdx '\..*|.*/\.[^/]*$|.*/\..*/.*$|_.*' . gs://my-bucket.com/path
#Where the exclude pattern has 4 components separated by | characters.

\..*        <- excludes .files and .directories in the current directory
.*/\.[^/]*$ <- excludes .files in subdirectories
.*/\..*/.*$ <- excludes .directories in subdirectories
_.*         <- excludes _files and _directories


#example
gsutil rsync -dr -x '.*/\.[^/]*$|.*/\..*/.*$|.*/assets.*$|.*/theme.*$' workspace/ gs://bucket/vix/
--

##BACKUP GIT AND TAR TO STORAGE

cd $HOME/workspace/ && for d in * ; do cd $HOME/workspace/$d'/'; echo "pulling $d"; git pull; cd $HOME/workspace; tar -zcvf $HOME/tmp/$d.tar.gz --exclude .git $d; done; cd && gsutil -m mv $HOME/tmp/* gs://BUCKET-NAME/DIR/ && exit


##BACKUP GIT AND RSYNC TO STORAGE

cd $HOME/workspace/ && for d in * ; do cd $HOME/workspace/$d'/'; echo "pulling $d"; git checkout master && git reset --hard && git pull; cd $HOME/workspace; tar --exclude '.git' --exclude 'assets' --exclude 'theme' -zcvf $HOME/tmp/$d.tar.gz $d; done; cd && gsutil -m mv $HOME/tmp/* gs://BUCKET-NAME/DIR/ && exit


##public files
gsutil -m acl set -R -a public-read gs://bucket
gsutil defacl set public-read gs://bucket
